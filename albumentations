import warnings

warnings.filterwarnings('ignore')
import os, shutil, cv2, tqdm
import numpy as np
import albumentations as A
from PIL import Image
from multiprocessing import Pool
from typing import Callable, Dict, List, Union

# https://github.com/albumentations-team/albumentations




ENHANCEMENT_LOOP = 3
ENHANCEMENT_STRATEGY = A.Compose([
    A.Compose([
        A.Affine(rotate=[-15, 15], keep_ratio=True,
                 p=0.5),  # Augmentation to apply affine transformations to images.

        A.ElasticTransform(p=0.1),  # Elastic deformation of images as described in [Simard2003]_ (with modifications).
        A.Flip(p=0.1),  # Flip the input horizontally


    ], p=1.0),

    A.Compose([
        A.Blur(p=0.1),  # Apply Gaussian noise to the input image.
        A.ISONoise(p=0.1),  # Apply camera sensor noise.
        A.RandomBrightnessContrast(p=0.1),  # Randomly change brightness and contrast of the input image.
        A.ToGray(p=0.1),  # Convert the input RGB image to grayscale
    ], p=1.0)

    # A.OneOf([
    #     A.GaussNoise(p=1.0), # Apply Gaussian noise to the input image.
    #     A.ISONoise(p=1.0), # Apply camera sensor noise.
    #     A.ImageCompression(quality_lower=50, quality_upper=100, p=1.0), # Decreases image quality by Jpeg, WebP compression of an image.
    #     A.RandomBrightnessContrast(p=1.0), # Randomly change brightness and contrast of the input image.
    #     A.RandomFog(p=1.0), # Simulates fog for the image.
    #     A.RandomRain(p=1.0), # Adds rain effects to an image.
    #     A.RandomSnow(p=1.0), # Bleach out some pixel values imitating snow.
    #     A.RandomShadow(p=1.0), # Simulates shadows for the image
    #     A.RandomSunFlare(p=1.0), # Simulates Sun Flare for the image
    #     A.ToGray(p=1.0), # Convert the input RGB image to grayscale
    # ], p=1.0),
], bbox_params=A.BboxParams(format='yolo', min_visibility=0.1, label_fields=['class_labels']))


def parallelise(function: Callable, data: List, chunksize=100, verbose=True, num_workers=os.cpu_count()) -> List:
    num_workers = 1 if num_workers < 1 else num_workers  # Pool needs to have at least 1 worker.
    pool = Pool(processes=num_workers)
    results = list(
        tqdm.tqdm(pool.imap(function, data, chunksize), total=len(data), disable=not verbose)
    )
    pool.close()
    pool.join()
    return results


def draw_detections(box, name, img):
    height, width, _ = img.shape
    xmin, ymin, xmax, ymax = list(map(int, list(box)))

    # 根据图像大小调整矩形框的线宽和文本的大小
    line_thickness = max(1, int(min(height, width) / 200))
    font_scale = min(height, width) / 500
    font_thickness = max(1, int(min(height, width) / 200))
    # 根据图像大小调整文本的纵向位置
    text_offset_y = int(min(height, width) / 50)

    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), line_thickness)
    cv2.putText(img, str(name), (xmin, ymin - text_offset_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0),
                font_thickness, lineType=cv2.LINE_AA)
    return img


def show_labels(images_base_path, labels_base_path):
    if os.path.exists(SHOW_SAVE_PATH):
        shutil.rmtree(SHOW_SAVE_PATH)
    os.makedirs(SHOW_SAVE_PATH, exist_ok=True)

    for images_name in tqdm.tqdm(os.listdir(images_base_path)):
        file_heads, _ = os.path.splitext(images_name)
        # images_path = f'{images_base_path}/{images_name}'
        images_path = os.path.join(images_base_path, images_name)
        # labels_path = f'{labels_base_path}/{file_heads}.txt'
        labels_path = os.path.join(labels_base_path, f'{file_heads}.txt')
        if os.path.exists(labels_path):
            with open(labels_path) as f:
                labels = np.array(list(map(lambda x: np.array(x.strip().split(), dtype=np.float64), f.readlines())),
                                  dtype=np.float64)
            images = cv2.imread(images_path)
            height, width, _ = images.shape
            for cls, x_center, y_center, w, h in labels:
                x_center *= width
                y_center *= height
                w *= width
                h *= height
                draw_detections([x_center - w // 2, y_center - h // 2, x_center + w // 2, y_center + h // 2],
                                CLASSES[int(cls)], images)
            # cv2.imwrite(f'{SHOW_SAVE_PATH}/{images_name}', images)
            cv2.imwrite(os.path.join(SHOW_SAVE_PATH, images_name), images)
            print(f'{SHOW_SAVE_PATH}/{images_name} save success...')
        else:
            print(f'{labels_path} label file not found...')


def data_aug_single(images_name):
    file_heads, postfix = os.path.splitext(images_name)
    # images_path = f'{IMAGE_PATH}/{images_name}'
    images_path = os.path.join(IMAGE_PATH, images_name)
    # labels_path = f'{LABEL_PATH}/{file_heads}.txt'
    labels_path = os.path.join(LABEL_PATH, f'{file_heads}.txt')
    if os.path.exists(labels_path):
        with open(labels_path) as f:
            labels = np.array(list(map(lambda x: np.array(x.strip().split(), dtype=np.float64), f.readlines())),
                              dtype=np.float64)
        images = Image.open(images_path)
        for i in range(ENHANCEMENT_LOOP):
            # new_images_name = f'{AUG_IMAGE_PATH}/{file_heads}_{i:0>3}{postfix}'
            new_images_name = os.path.join(AUG_IMAGE_PATH, f'{file_heads}_{i:0>3}{postfix}')
            # new_labels_name = f'{AUG_LABEL_PATH}/{file_heads}_{i:0>3}.txt'
            new_labels_name = os.path.join(AUG_LABEL_PATH, f'{file_heads}_{i:0>3}.txt')
            try:
                transformed = ENHANCEMENT_STRATEGY(image=np.array(images),
                                                   bboxes=np.minimum(np.maximum(labels[:, 1:], 0), 1),
                                                   class_labels=labels[:, 0])
            except:
                continue
            transformed_image = transformed['image']
            transformed_bboxes = transformed['bboxes']
            transformed_class_labels = transformed['class_labels']

            cv2.imwrite(new_images_name, cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR))
            with open(new_labels_name, 'w+') as f:
                for bbox, cls in zip(transformed_bboxes, transformed_class_labels):
                    f.write(f'{cls} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n')
            print(f'{new_images_name} and {new_labels_name} save success...')
    else:
        print(f'{labels_path} label file not found...')


def data_aug():
    if os.path.exists(AUG_IMAGE_PATH):
        shutil.rmtree(AUG_IMAGE_PATH)
    if os.path.exists(AUG_LABEL_PATH):
        shutil.rmtree(AUG_LABEL_PATH)

    os.makedirs(AUG_IMAGE_PATH, exist_ok=True)
    os.makedirs(AUG_LABEL_PATH, exist_ok=True)

    for images_name in tqdm.tqdm(os.listdir(IMAGE_PATH)):
        data_aug_single(images_name)


if __name__ == '__main__':
    data_aug()

    show_labels(IMAGE_PATH, LABEL_PATH)
    show_labels(AUG_IMAGE_PATH, AUG_LABEL_PATH)
