Distinguishing difficulty imbalance strawberry ripeness instances under complex farmland environment
Yang Gan 1, Xuefeng Ren 1, Huan Liu 1, Yongming Chen 1, and Ping Lin 1,*
Citation: To be added by editorial staff during production.
Academic Editor: Firstname Lastname
Received: date
Revised: date
Accepted: date
Published: date

Copyright: © 2024 by the authors. Submitted for possible open access publication under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).
1School of Electrical Engineering and Automation, Hubei Normal University, Huangshi 435002, China
*	Correspondence: pinglin007@hbnu.edu.cn; Tel.: +86 15151009725
Abstract: The existing strawberry ripeness detection algorithm has problems of low precision and high missing rate in the real complex scene. Therefore, we propose a novel model based on a hybrid attention mechanism. Firstly, a partial convolution based compact inverted block is developed, which significantly enhances the feature extraction capability of the model. Secondly, an efficient partial hybrid attention mechanism is established, which realizes the remote dependence and accurate localization of strawberry fruit. Meanwhile, a multi-scale progressive feature pyramid network is constructed, and the fine-grained features of strawberry targets of different sizes are accurately extracted. Finally, a Focaler-shape-IoU loss function is proposed to effectively solve the problem of difficulty imbalance between strawberry samples and the influence of the shape and size of the bounding box on regression. The experimental results show that the model’s precision and mAP0.5 reach 92.1% and 92.7%, respectively, which are 2.0% and 1.7% higher than the baseline model. Additionally, our model performs better in detection performance than most models with fewer parameters and lower FLOPs. In summary, the model can accurately identify the maturity of strawberry fruit under complex farmland environments and provide certain technical guidance for automated strawberry picking robots.
Keywords: Strawberry ripeness; Object detection; Difficulty imbalance; Farmland environment

1. Introduction
Strawberries are not only a pleasant and nutritious fruit but also play an important role in global dietary needs and agricultural research [1]. According to data from relevant UN organizations, the strawberry market is currently in a steady growth phase, underscoring its globally significant position and the increasing demand trend [2]. However, strawberries ripen rapidly, are easily damaged, and are prone to rot if not harvested in time, which can result in substantial economic losses [3]. While traditional manual picking methods have a long history, they generally rely on the experience of the picker, which introduces subjectivity and can lead to misclassification of strawberries, thereby affecting overall fruit quality. Therefore, accurately estimating the yield and quality of strawberries is crucial for farmers, as it aids in planning, optimizing the harvesting process, enhancing operational efficiency, and promoting sustainable economic development [4]. To boost productivity and harvesting efficiency, there is an urgent need for the development of a strawberry harvesting robot. However, the picking accuracy of the robot can only surpass that of manual picking when the fruit is identified with a certain degree of precision [5], emphasizing the critical importance of accurate strawberry ripeness detection.
In recent years, the application of deep learning technologies in agriculture has become increasingly widespread. Specifically, convolutional neural networks (CNNs) have revolutionized object detection, offering unprecedented accuracy in both object detection and classification [6]. Compared to traditional visual processing algorithms, deep neural networks (DNNs) have been extensively adopted in crop object detection due to their superior feature extraction and self-learning capabilities [7]. Moreover, the integration of traditional agricultural practices with deep learning innovations has emerged as a major trend, driving the rapid advancement of agricultural informatization and automation [8]. Deep learning-based methods have also demonstrated excellent performance in strawberry detection. Tang et al. [9] developed a Mask R-CNN-based model for classifying strawberry ripeness in complex field environments. However, the high complexity and low computational efficiency of the model limit its widespread application. Pang et al. [10] proposed a lightweight YOLO-based algorithm that accurately identifies strawberry ripeness in complex backgrounds. Experimental results indicate that the model size is only 7.44 MB and the mAP0.5, achieved 0.956, demonstrating its potential for deployment in strawberry harvesting robots. Conversely, Yang et al. [11] introduced the BCo-YOLOv5 model, which was successfully applied to fruit target detection in orchards, with significantly lower computational complexity compared to Fast R-CNN, making it suitable for real-time object detection scenarios. Furthermore, Wang et al. [12] proposed the DSE-YOLO network, which can accurately detect strawberries at various stages of ripeness in natural scenes. Recently, Yang et al. [13] launched the LS-YOLOv8s model, which integrates Swin-Transformer and multi-head self-attention mechanisms, significantly improving the accuracy of strawberry ripeness detection. Building on this, Wang et al. [14] proposed a YOLOv8-based model for identifying ripe and unripe strawberries. By analyzing the hue, saturation, and value (HSV) channels, the model counts the red pixels along the central line of ripe strawberries, enabling rapid and accurate identification of strawberries at different ripeness stages in controlled environments. Additionally, Chen et al. [15] enhanced the YOLOv8 model by replacing some of the C2f modules in the backbone with ConvNeXtV2 modules, which improved the model's ability to capture features across different maturity levels of strawberries.
Although these algorithms have been demonstrated to be deployable for strawberry ripeness detection tasks, the applicability of these models in most real-world complex environments continues to face significant challenges. To address this issue, a novel detection model based on YOLOv8n has been developed. Initially, the backbone of the original model was redesigned to extract features from strawberry targets. It led to a 2.4% increase in model parameter counts but improved performance in detecting complex strawberries that are overlapping, occluded, or exhibit colors similar to the background. Considering the limited receptive field of CNNs, which hampers the capture of global features, it was noted that Transformers [16] possess the ability to simulate global contextual information, a feature that CNNs lack. Therefore, the combination of multi-head self-attention (MHSA) from Transformers with CNNs was considered to fully leverage the strengths of both. A lightweight multi-head self-attention (LMSA) was invented to reduce the computational cost of MHSA. LMSA was again coupled with an efficient local attention (ELA) [17] mechanism to create an efficient partial hybrid attention mechanism (PHAM). This mechanism was introduced solely at the lowest resolution at the bottom of the backbone network to avoid excessive computational burden associated with self-attention. This design not only integrated global learning capabilities into the model but also improved its ability to locate regions of strawberries at different ripeness levels.
Additionally, to address the insufficient feature fusion capabilities of the original neck network, a multi-scale progressive feature pyramid (MS-FPN) was constructed, integrated with PHAM by incorporating adaptively spatial feature fusion (ASFF) [18] technology and an efficient DySample upsampler [19]. This approach effectively reduced the loss of key information during the upsampling process and enhanced feature fusion capabilities, thereby improving the model performance of detecting fine-grained features of strawberries with various sizes and at different ripeness levels. Finally, taking the predominantly heart-shaped or slightly flattened round shapes of strawberries into account, the Focaler-shape-IoU method was leveraged to emphasize the impact of boundary box shapes and scales, improving the recognition accuracy of challenging samples in complex scenes.The main contributions of this study are summarized as follows:
(1)A compact inverted module (PCIB) based on partial convolution (Pconv) module was designed to replace the bottleneck structure of C2f module in the backbone network, significantly capturing the key features of strawberries at different ripeness levels.
(2)The ELA mechanism was combined with the LMSA mechanism to create the PHAM attention mechanism, which enhances the ability of the model to perceive long-range information and capture the location of strawberry target areas with reduced computational cost.
(3)The MS-FPN integrated with the PHAM was constructed by merging the ASFF unit and an efficient DySample upsampler. Advanced features with multidimensional spatial information and position sensitivity processed by the PHAM were gradually incorporated into the feature fusion process, effectively improving the information transmission ability between network channels.
(4)The issue of imbalance in difficulty among strawberry samples was effectively addressed by integrating the Focaler-IoU and Shape-IoU loss functions, significantly improving the accuracy of boundary box regression for strawberries at different ripeness levels.
The remainder of the article is organized as follows. Section 2 introduces the specific algorithm, while Section 3 presents and discusses the experimental results. Section 4 summarizes the main conclusions, analyzes existing limitations, and offers prospects for future research directions.
2. Materials and Methods
2.1. Image Acquisition
We referred to the maturity definition standards for strawberries from the literature [4] and divided the strawberry growth process for target detection into three stages: raw, turning, and tipe. Raw stage indicates strawberries at this stage exhibiting pure white or green colors; Turning stage denotes strawberries during this time transiting from pink to light red, with color coverage ranging from 0% to 80%; Ripe stage represents strawberries in deep red, and the color coverage exceeding 80%. To accurately detect strawberry maturity, we collected and constructed four different strawberry datasets to validate our algorithms:
(1)StrawDI_Db1 Strawberry Dataset: This is a high-quality open-source dataset specifically designed for strawberries, sourced from approximately 150 hectares of strawberry plantations in Huelva Province, Spain, and includes 2,700 strawberry images (https://strawdi.github.io/).
(2)Straw_Det Strawberry Dataset: A total of 1,500 strawberry images were collected from the Roboflow platform (https://robotflow.com/), primarily from the Strawberry-Detection Dataset and Strawberry-Detection2 Dataset.
(3)Straw_Cul Strawberry Dataset: A total of 1,400 images of strawberries were captured using a smartphone under various lighting conditions. The shooting scenes spanned both indoor and outdoor environments, from 6:00 AM to 6:00 PM, encompassing various weather conditions such as sunny and overcast days.
(4)SBDS Strawberry Dataset: This custom strawberry dataset, comprising a total of 5,600 images, was created by merging the self-captured Straw_Cul dataset with the open-source datasets Straw_Det and StrawDI_Db1.
The SBDS dataset aggregates strawberry images from various complex environments, vividly illustrating the diverse conditions of strawberry growth environments and the variability of strawberry instances. Representative samples from different environments are shown in Figure 1. Dark and humid conditions, as depicted in Figure 1a2, a3, and c1, may lead to reduced image quality, while complex and dense growth scenarios, shown in Figure 1b1 and c1, may interfere with accurate strawberry detection. Additionally, occlusions caused by surrounding leaves, as seen in Figure 1a4, b4, and c4, may result in missed detections, further reducing detection accuracy. Strong sunlight, illustrated in Figure 1c2, can cause overexposure or deep shadows in certain areas of the image, making it difficult for the model to accurately identify object contours and features. Variations in background color contrast, as shown in Figure 1a1 , necessitate more complex detection algorithms to address these challenges. To validate the robustness of the proposed method, a comprehensive evaluation was conducted on the four different strawberry datasets.

Figure 1. Representative strawberry samples from three different datasets: Straw_Cul (a1-4), StrawDI_Db1 (b1-4), and Straw_Det (c1-4).
2.2. Data Augmentation
To realistically simulate complex strawberry growth environments, various pixel-level and spatial transformations were employed for data augmentation, utilizing a range of image processing techniques from the Albumentations library (https://github.com/albumentations-team/albumentations). This approach significantly enhanced the expressiveness of the strawberry dataset. Specifically, for the strawberry ripeness detection task, the following augmentation techniques were applied:
(1)Flip: Horizontal flipping was used to simulate different orientations of strawberries in the images, allowing the model to learn features from varied perspectives and increasing its ability to generalize to real-world scenarios where strawberries may appear in different orientations.
(2)Blur: Gaussian blur and motion blur were applied to the images to simulate varying environmental conditions such as different lighting or slight motion. This helps the model learn to focus on key features even when the image quality is compromised or when strawberries are partially obscured.
(3)Rotation: Random rotation of the images within a specified range was used to simulate strawberries at different angles. This augmentation helps the model become invariant to the orientation of the fruit, enhancing its ability to detect strawberries in diverse poses.
(4)Mosaic: Mosaic augmentation involves combining multiple images into one composite image, which helps the model become more robust to occlusions and varying backgrounds. This technique also introduces diversity by providing the model with a wider range of scenarios in a single training sample.
These augmentation strategies help improve the model's ability to handle real-world variations in strawberry appearance and environmental conditions, thereby enhancing its performance and robustness in detecting strawberries at various ripeness stages.Through these meticulously designed data augmentation techniques, not only was the natural growth environment of strawberries effectively simulated, but the diversity of the data and the robustness of the model were also significantly enhanced. Initially, the SBDS dataset contained 6,784 green strawberries, 4,377 strawberries at the turning stage, and 14,674 ripe strawberries. After the dataset was split into training, validation, and testing sets in a 6:2:2 ratio, the data augmentation techniques were applied to the dataset As a result, the total number of images in the dataset grew to 16,800, with the number of samples for each ripeness category increasing to 20,352 green strawberries, 13,131 strawberries at the turning stage, and 44,022 ripe strawberries. This expanded dataset significantly enhanced the diversity and robustness of the model, ensuring its effectiveness in training and evaluation.
2.3. Framework of HM-YOLO
We propose a single-stage detection model of HM-YOLO to improve the detection accuracy of strawberries at different maturities in complex growth environments. As illustrated in Figure 2, firstly, the bottleneck structure in the C2f module is replaced with PCIB in the backbone network to achieve efficient feature extraction. Secondly, the MS-FPN unit is used instead of the original path aggregation network-feature pyramid networks (PAN-FPN) in the neck network to enable more efficient multi-scale feature fusion, which allows for precise identification and extraction of fine-grained features of strawberries at various maturities. Finally, the Focaler-shape-IoU loss function in the prediction head part is adopted in place of the CIoU loss function to address the issues related to varying difficulty levels between strawberry samples and the impact of bounding box shape and size on regression. In the following sections, a detailed description of the model will be provided.

Figure 2 The structure of the HM-YOLO.
2.3.1. Compact Inverted Module (PCIB) Based on Pconv
To enhance the global feature extraction capability of the backbone network, a new C2fPCIB module is developed based on the original C2f module of the YOLOv8n model. The C2fPCIB module integrates the Pconv block and PCIB proposed in this study. This design retains the structure of the original C2f module while inheriting its multi-gradient information flow capability and achieving efficient feature extraction with a lower number of parameters and computational cost.
As shown in Figure 3, the similarity of features between different channels is visually demonstrated through the visualized strawberry feature maps, indicating the presence of a certain degree of channel redundancy in the feature maps. Thus, further cost optimization of the model becomes feasible.

Figure 3 Original strawberry image(a) and its corresponding feature maps (b)-(i) reflecting significant redundancy in different channels.
To solve above issues, Chen et al. [20] proposed a Pconv operator (see Figure 4b), which effectively reduces redundant computations and memory accesses by applying filters only to selected input channels without interfering with other channels, thereby enhancing the utilization efficiency of spatial features. Assuming that the input and output feature maps have the same number of channels, denoted as , where  represents the kernel size, and  indicates the number of Pconv channels. The FLOPs of Pconv are only , given that the bias ratio , which is only 1/16 of those required for conventional convolution. Additionally, the memory access volume of Pconv, as shown in equation (1), is approximately 1/4 of the original value. Clearly, Pconv significantly enhances model processing speed and can effectively extract subtle features from strawberry images.
							
	We developed an innovative compact transpose block (PCIB) based on the Pconv operator to replace the original Bottleneck structure in the C2f module of the backbone network. As shown in Figure 4a, this module primarily consists of three Pconv Blocks and two 1×1 convolutional layers. To maintain feature diversity while reducing computational delay, normalization and activation layers are used only after dimensionality expansion and reduction through the 1×1 convolutional layers. Figure 4c illustrates the structural design of the Pconv Block, which mainly includes the Pconv operator and 1×1 convolutional layers. Additionally, residual connections [21] are incorporated to effectively prevent issues of gradient explosion or vanishing during multi-layer stacking.

Figure 4 The components of the PCIB: (a) PCIB, (b) Partial Convolution, and (c) Pconv Block.
2.3.2. Partial Hybrid Attention Mechanism (PHAM)
The growth environment of strawberries is complex and variable, with their shape and color changing with maturity, which can lead to the loss of key feature information and increase the risk of missed and false detections [22]. To address this issue, PHAM model is developed, with its structure detailed in Figure 5. PHAM model integrates LMSA and ELA. Specifically, the input features are first processed through the Pconv Block to enhance the learning capability of local features, the features are processed by a CBS module with a 1×1 convolutional kernel, which divides the features into following two equal parts based on the number of feature channels:
																
																
where,  denotes the Pconv Block, and  represents the CBS module with a 1×1 convolution kernel. The channel dimension of feature  is evenly divided, with the first half of the channels forming  and the second half forming ​.  is further processed through a residual block composed of PHAM and ELA, and this processed feature  is subsequently handled by a residual block consisting of a feedforward neural network (FFN). This residual block contains two CBS modules with a 1×1 convolution kernel. The derivation of the intermediate features  and is described  by formulas (4) and (5).
													
																	
where  denotes efficient local attention,  represents lightweight multi-head self-attention, and  signifies the feedforward neural network. Finally, the processed and unprocessed feature parts are concatenated and fused using the CBS module with a 1×1 convolution kernel to obtain the output feature Y, as described by:
															
This structures significantly reduce the demand for computational resources and greatly enhances the ability of the model to identify and select key features in the strawberry maturity detection task, allowing the model to more accurately capture and utilize important feature information.

Figure 5 Partial hybrid attention mechanism.
The ELA mechanism is integrated into the PHAM framework. The ELA module precisely assists the model in locating the regions of different maturity levels of strawberry targets, while introducing only a small number of additional parameters, but significantly enhancing the overall performance of the model. The detailed process of the ELA operation is illustrated in Figure 6a. For a given input feature map, the process begins with two types of spatial average pooling on each channel: one spanning the height and a single width (horizontal pooling) and the other spanning the width and a single height (vertical pooling). These operations capture spatial dependencies in both directions. After pooling, a one-dimensional convolution enhances positional information in both directions, refining the spatial relationships. Next, position attention representations are generated using group normalization and a nonlinear activation function. The group normalization standardizes activations, while the HardSigmoid activation function, chosen for its efficiency, accelerates processing. The resulting positional attention is then used to generate the final output of the ELA module.
The self-attention mechanism exhibits high computational complexity and memory usage. To address this, we propose a LMSA module, as illustrated in Figure 6b. This module enables simultaneous computation of multiple self-attentions to capture relevant information in different subspaces. LMSA is equipped with 8 heads, and following the literature [23], we halve the dimensions of queries and keys. This modification not only maintains the performance of the model but also significantly improves computational efficiency. Furthermore, we replace the traditional LayerNorm [24] with BatchNorm, further accelerating the inference speed of the model. These optimizations allow LMSA to significantly improve processing speed and efficiency while maintaining accuracy.
The input feature map is denoted as , where  represents the number of channels in the input tensor, and  and  denote the height and width of the input tensor, respectively.  is the number of heads,  is the output dimension of the  and , and  has  channels. First, a convolution operation with a kernel size of 1×1 is applied to the input feature map, followed by batch normalization, resulting in three homogeneous tensors: queries, keys, and values, as described by formula (12). These tensors each contain rich contextual information.
														
where,, , and  are the query, key, and value matrices, respectively.
Each head in the LMSA captures different aspects of the input data, and the outputs of all heads are subsequently combined into the final output to achieve more comprehensive information integration:
															

Figure 6 (a) ELA module and (b) LMSA module.
The LMSA attention mechanism significantly enhances the accuracy and robustness of strawberry maturity detection in complex environments by capturing global spatial dependencies and emphasizing critical features. This approach is particularly valuable in scenarios where strawberries overlap or are occluded, enabling the model to precisely focus on key maturity cues, thereby greatly improving its detection performance in overlapping or occluded situations.
2.3.3. Multi-scale Progressive Feature Fusion Network (MS-FPN)
In the strawberry dataset, the strawberry ripeness detection task faces numerous challenges, particularly regarding the detection of strawberries at different scales under variable environmental conditions. For example, strawberries exhibit significant size differences at various ripeness stages, and the detailed features of small strawberries are prone to being confused with the environment in complex backgrounds. These factors collectively increase the difficulty of accurately recognizing strawberry ripeness, necessitating advanced and flexible feature fusion methods to enhance detection performance. Although the original YOLOv8 model employs the PAN-FPN structure in the neck network to facilitate fusion across different feature layers, its upsampling module may lead to the loss of critical image details when processing feature maps. To address these limitations, the MS-FPN has been developed, with the specific feature fusion process illustrated in Figure 7. Specifically, the MS-FPN replaces the traditional upsampling module with an efficient DySample module, effectively improving the detection efficiency of the model. Subsequently, the ASFF module is used to merge two adjacent low-level features, allowing the model to effectively capture feature details at different scales and dynamically adjust the weights of each feature layer to enhance the transmission of fundamental feature information. Finally, these low-level features are efficiently fused with high-level features, which have been processed by PHAM to possess multi-dimensional spatial information and positional sensitivity. This fusion method not only incorporates rich semantic information but also significantly enhances the capability of the model to detect fine-grained features in strawberry images, thereby improving the overall detection performance.

Figure 7 Workflow diagram of feature fusion through MS-FPN.
To address potential multi-object information conflicts during the feature fusion process of the PAN-FPN feature pyramid, the original YOLOv8 model structure was improved by integrating the ASFF unit to enhance feature fusion effectiveness. The ASFF unit allows for adaptive, selective fusion across different feature scales, reducing interference from information conflicts and improving the model's adaptability and detection accuracy in multi-object scenarios. The fusion process is illustrated in Figure 8. Specifically,  represents the feature vector at position  from layer  to layer . Through the adaptive spatial fusion technique of multi-level features, the final feature vector  can be obtained as a linear combination of feature vectors  and , with the specific relationship outlined as follows:
															
where, and  represent the spatial weights of two different feature levels on layer , and these weights are constrained by:
																	

Figure 8 ASFF-based feature fusion module.
To align feature dimensions, 11 convolutions were used to reduce the number of channels in the features. Subsequently, features were upsampled using the DySample technique. Conversely, during downsampling, a 33 convolution with a stride of 2 was employed, which not only reduced the resolution but also adjusted the number of channels. ASFF enhanced the importance of critical layers by assigning different spatial weights to features at various levels, thereby enabling effective feature fusion by the model.
Although the YOLOv8 model utilizes nearest-neighbor interpolation for upsampling, several dynamic upsampling techniques such as content-aware reassembly of features (CARAFE), feature aggregation and decoding (FADE), and similarity-aware point association (SAPA) have been developed, which have significantly improved detection performance. However, these dynamic upsamplers are typically more complex in structure and consume more inference time compared to nearest-neighbor interpolation. To reduce inference latency and enhance computational speed, this study introduces a lightweight and efficient dynamic upsampler, DySample.
DySample employs point sampling techniques, which require fewer computational resources and do not necessitate custom CUDA packages. Consequently, its parameters, FLOPs, GPU memory usage, and latency are significantly lower compared to upsamplers relying on dynamic convolution kernels. The module structure of DySample is illustrated in Figure 9. Specifically, the input feature map  is processed by the sampling point generator to produce a sampling set . Here,  represents the upsampling scale factor, and  denotes the dimensions of the  and  coordinates of the original feature map . Subsequently, the grid sampling function uses the coordinate positions in the sampling set  to upsample the input feature map, generating . The design of the DySample dynamic upsampler is highly flexible, allowing for dynamic generation of sampling points based on specific task requirements, thus optimally adapting to the detection needs of strawberry ripeness in complex environments. This upsampler not only enhances model performance but also improves resource utilization efficiency.

Figure 9 Dysample network structure.

2.3.4. Focaler-shape-IoU Loss Function
YOLOv8 originally used CIoU [25] as the loss function for bounding boxes, which performs well in box overlap, center distance, and shape similarity. However, it lacks sensitivity to small targets like strawberries and struggles with complex environments and sample imbalance. To address these issues, the Focaler-shape-IoU loss function combines Focaler-IoU and Shape-IoU to improve sensitivity to small and irregular strawberry targets.
Shape-IoU focuses on the impact of bounding box shape and scale, making it particularly well-suited to address the diverse shapes of strawberries. By incorporating the actual shape and scale of the strawberries into the loss computation, it is better able to adapt to and recognize various shapes of strawberries, thereby improving both detection accuracy and recall. The Shape-IoU is calculated as follows:
																
where  represents the ratio of the intersection area to the union area between the predicted bounding box and the ground truth bounding box. Here,  denotes the predicted box, and  denotes the ground truth box. Additionally, the weight coefficients for horizontal and vertical directions,  and  are introduced:
															
															
where the scale factor  is closely related to the size of strawberries in the dataset. The weight coefficients for horizontal and vertical directions, and , are adjusted according to the shape of the ground truth box. The distance cost is defined as follows:
									
where , , and  collectively define the shape cost, with the calculation process detailed in equation (20). In this equation, the value of  is a crucial component, as it controls the degree of emphasis placed on the shape cost.
														
where  and  represent the ratios of the weighted differences in width and height, with the calculation formula provided in equation (21). Here,  and  denote the width and height of the ground truth box, respectively.
															
The calculation expression for the Shape-IoU bounding box regression loss is given as follows:
											
Focaler-IoU enhances model focus on difficult samples—such as occluded, small, or background-similar objects—by increasing their relative weight during training. This improves recognition accuracy for challenging samples and balances the model's attention by reducing the weight of easier ones, thereby enhancing generalization and robustness. The IoU loss is redefined by Focaler-IoU using a linear interval mapping method, as detailed below:
												
where  represents the reconstructed Focaler-IoU, with . By adjusting the values of  and , Focaler-IoU can be effectively directed to focus on different regression samples. The Focaler-IoU loss function is defined as follows:
															
By incorporating the Focaler-IoU loss into the Shape-IoU bounding box regression loss function, the Focaler-shape-IoU loss function is formulated:
											
Overall, the Focaler-shape-IoU loss function combines the emphasis of Shape-IoU on shape and scale with the focus of Focaler-IoU on difficult samples, effectively overcoming the limitations of existing methods and significantly improving the accuracy of strawberry maturity detection. After continuous adjustment of the hyperparameters of Focaler-shape-IoU, the parameter scale is set to 1.0, u to 0.95, and d to 0, which made the loss function suitable for the task of detecting strawberry maturity.
3. Results and Discussion
3.1. Experimental Setting
The experimental platform used in this study is the Ubuntu 22.04 operating system. The GPU model employed is the Nvidia GeForce RTX 4090 with a memory capacity of 24GB. The algorithm utilizes the PyTorch 2.0.1 deep learning framework and Python 3.10.13 as the programming language. The HM-YOLO network model was trained on the dataset with the following hyperparameter settings: a batch size of 64 was used, and the number of epochs was set to 200 based on early stopping criteria and the observation that training loss had stabilized without further reduction. The model was optimized using the method of stochastic gradient descent.
3.2. Evaluation Metrics
The performance of the model was evaluated using four metrics: precision (P), recall (R), and mean average precision (mAP). The formulas for calculating precision and recall are shown as follows:
									
where  represents the number of targets that the model correctly detected,  represents the number of non-targets that the model incorrectly detected as targets, and  represents the number of actual targets that the model failed to detect.
The mAP is an indicator of the average AP (Average Precision) value across all categories, which is used to comprehensively evaluate the performance of the model in multi-class target detection tasks. The formula for calculating mAP can be expressed as:
																							
where  represents the number of classes, with  being set to 3 in this case.  denotes the average precision for the  class. mAP0.5 represents the total class average accuracy at an IoU threshold of 0.5, mAP0.75 represents the total class average accuracy at an IoU threshold of 0.75, and MAP0.5:0.95 represents the average accuracy at different IoU thresholds, which range from 0.5 to 0.95 in increments of 0.05.
3.3. Validation on Different Datasets
The improved HM-YOLO model was evaluated using four different strawberry datasets to assess its performance in recognizing strawberries at various stages of ripeness, and its detection performance was compared with the baseline model of YOLOv8n. As shown in Table 1, the HM-YOLO model achieved improvements of 1.6% and 1.2% in the mAP0.5 and mAP0.5:0.95, respectively, on the SBDS dataset, which has the largest number of samples. Additionally, the precision and recall of the HM-YOLO model increased across all four datasets. Notably, the highest accuracy improvement of 2.5% was observed on the Straw_Cul dataset, while the most significant recall improvement of 1.5% was seen on the Straw_Det dataset. This phenomenon may be related to the greater impact of individual samples on overall performance in datasets with fewer samples. Overall, the HM-YOLO model significantly outperformed the baseline model in key performance metrics such as precision, recall, and mAP, demonstrating that the improved model is well-suited to replace the baseline model for detecting strawberries at different ripeness stages in relatively complex environments.
Table 1 The precision, recall, mAP0.5, and mAP0.5:0.95 obtained from the baseline model and the proposed model across the SBDS, StrawDI_Db1, Straw_Det, and Straw_Cul datasets.
Dataset	Models	Precision	Recall	mAP0.5	mAP0.5:0.95
SBDS	Baseline	90.1	85.2	91.0	75.1
	Improved	92.1	86.5	92.7	76.3
StrawDI_Db1	Baseline	91.9	87.9	93.7	79.1
	Improved	93.6	89.2	94.7	80.0
Straw_Det	Baseline	86.5	79.9	85.9	70.2
	Improved	88.4	81.4	87.6	71.4
Straw_Cul	Baseline	80.8	77.0	82.0	60.9
	Improved	83.3	78.4	83.5	62.2
3.4. Impact of Different Attention Mechanisms
To validate the superiority of the proposed PHAM method, the GradCAM method [26] was utilized to generate visual heat maps, and various attention mechanisms were compared for their effectiveness in focusing on strawberry fruit target areas on the SBDS dataset. Figure 10a shows the original strawberry image. Figure 10b presents the results of the original model without any attention mechanism.Figure 10c and d display the heat maps by applying the squeeze and excitation (SE) [27] and CBAM [28] attention mechanisms, respectively. Figure 10e, f, and g indicate the features processed with coordinate attention (CA) [29], ELA, and Transformer attention mechanisms, respectively, while Figure 10h illustrates the results generated by using the PHAM.
It can be observed that the YOLOv8n model demonstrates weak focus on strawberries when no attention mechanism was embedded. Although the SE and CBAM mechanisms improved attention to strawberries to some extent, the enhancement remained limited. In contrast, the CA, ELA, and Transformer attention mechanisms exhibited superior performance in enhancing the focus on strawberries, though CA attention still fell short in focusing on smaller strawberries. The proposed PHAM method not only improves the heat map coverage of strawberry locations but also enhanced the focus on smaller strawberries, achieving more precise positioning. These results confirmed that the PHAM effectively integrated contextual information from the surrounding environment, focusing on more critical strawberry fruit pixel areas, thus significantly boosting the detection performance.

Figure 10 Original image(a) and heat maps generated under the different attention mechanisms of: (b) no attention, (c) SE, (d) CBAM, (e) CA, (f) ELA, (g) Transformer, and (h) PHAM.
3.5. Comparison of Different Feature Fusion Methods
To validate the superiority of the proposed MS-FPN, the YOLOv8n algorithm with PAN-FPN was used as the baseline and compared with other advanced feature pyramid structures such as the BiFPN, HS-FPN [30], and AFPN [31] on the SBDS dataset. The experimental results were presented in Table 2. After incorporating the BiFPN, HS-FPN, and AFPN into the baseline model, improvements in the mAP metrics were observed. Among them, the model using the BiFPN structure achieved the highest improvement of 0.6% in mAP0.5. Although the MS-FPN showed a slight increase in the number of parameters and FLOPs, its mAP0.5, mAP0.75, and mAP0.5:0.95 increased by 1.1%, 0.8%, and 0.7%, respectively, demonstrating outstanding performance in strawberry ripeness detection. Compared to other advanced FPN models, MS-FPN exhibited a significant enhancement in overall detection accuracy. In summary, these results fully demonstrated the capability of MS-FPN in detecting fine-grained features in strawberry images and highlight its advanced nature in feature fusion methods.
Table 2 The comparative performance evaluation of different feature fusion architectures on the SBDS dataset.
Feature fusion structures	mAP0.5	mAP0.75	mAP0.5:0.95	Param.(M)	FLOPs(G)
Baseline	91.0	83.5	75.1	3.0	8.1
BiFPN [32]	91.6	84.0	75.4	2.9	7.3
HS-FPN [30]	91.3	83.6	75.3	2.0	7.0
AFPN [31]	91.4	83.8	75.4	3.2	7.4
Ours(MH-FPN)	92.1	84.3	75.8	3.9	11.0
3.6 Ablation Study
3.6.1. Attention Mechanism
To validate the impact of PHAM on the detection performance of the model within the proposed improvement methods, ablation experiments were designed using YOLOv8n as the baseline model on the SBDS dataset. In the experiments, the ELA and LMSA methods were added separately at the connection between the lowest resolution layer of the PAN-FPN feature pyramid structure and the backbone network for comparison. As shown inTable 3. The integration of either LMSA or ELA improved the precision recall, and mAP of the model. Notably, when LMSA and ELA were combined to form the complete PHAM mechanism, the model achieved the highest detection performance, with precision, recall, and mAP0.5 improving by 0.6%, 0.6%, and 0.7%, respectively. This result not only demonstrated that the integration of certain mixed attention mechanism modules could enhance the feature fusion capability of the FPN but also confirms the advantage of PHAM in reinforcing the contextual information perception of targets with varying maturity in strawberries, thereby effectively improving the detection performance.
Table 3 Ablation experiments of PHAM on the SBDS dataset.
LMSA	ELA	Precision	Recall	mAP0.5	mAP0.75	mAP0.5:0.95
		90.1	85.2	91.0	83.5	75.1
√		90.5	85.7	91.5	83.8	75.4
	√	90.4	85.4	91.3	83.7	75.3
√	√	90.7	85.8	91.7	83.9	75.5
3.6.2. IoU Loss Function
To validate the impact of the loss function module on the detection performance of the model within the proposed improvement methods, ablation experiments were conducted using the YOLOv8n model as the baseline on the SBDS strawberry dataset. As shown in Table 4, replacing the original CIoU loss function with the Shape-IoU loss function led to significant improvements in the precision, recall, and mAP0.5 of the model. This result indicates that considering the specific shape and size of strawberries when calculating the loss can effectively enhance the adaptability for strawberries of varying shapes. Notably, whether Focaler-IoU was coupled with CIoU or with Shape-IoU, positive effects on the precision, recall, and mAP0.5 were observed. This not only improved the accuracy of the model in recognizing challenging samples but also helped balance the focus of the model across all samples. Further analysis revealed that the combination of Focaler-IoU and Shape-IoU resulted in particularly significant improvements in precision, recall, and mAP0.5, with increases of 0.3%, 0.3%, and 0.4%, respectively. These experimental results not only validate that the introduction of Shape-IoU and Focaler-IoU can effectively enhance the detection performance of the model but also highlight the superiority of Focaler-shape-IoU in the task of strawberry ripeness detection.
Table 4 Ablation experiments of Focaler-shape-IoU on the SBDS dataset.
CIoU	Shape-IoU	Focaler-IoU	Precision	Recall	mAP0.5	mAP0.75	mAP0.5:0.95
√			90.1	85.2	91.0	82.7	75.1
√		√	90.4	85.4	91.2	82.9	75.2
	√		90.3	85.4	91.3	82.9	75.3
	√	√	90.4	85.5	91.4	83.1	75.3
3.6.3. Overall Strategies
To validate the effectiveness of the proposed strategy, a series of ablation experiments were conducted on the SBDS dataset (see Table 5). By replacing the bottleneck part of C2f in the backbone network with PCIB, an improvement of 0.3% in mAP0.5 was achieved compared to the baseline model, while the number of parameters only increased by 0.2M. This indicates that the replacement with PCIB effectively enhanced the feature extraction capability of the network without a significant increase in the number of parameters. Further, when MS-FPN was employed as the neck network, although there was an increase in the parameters and FLOPs of the model, precision and mAP0.5 improved by 1.2% and 1.0%, respectively. This improvement addressed the deficiencies in fine-grained information loss during the upsampling and feature fusion processes of existing feature pyramids. Additionally, with the inclusion of Focaler-shape-IoU, recall and mAP0.5:0.95 increased by 0.4% and 0.3%, respectively, which resolved the imbalance between easy and difficult samples and significantly enhanced detection accuracy in complex scenarios such as overlaps and occlusions. After integrating these strategies, our model achieved improvements of 2.0%, 1.3%, and 1.7% in precision, recall, and mAP0.5, respectively, compared to the baseline model. Although the parameters and computational complexity slightly increased, the model's information extraction and feature fusion capabilities were significantly enhanced. Notably, the model maintained real-time performance with an FPS reduction from 121.6 to 87.5, meeting the requirements for real-time deployment in strawberry ripeness detection. These results underscore the significant effectiveness of our model in improving detection performance while maintaining feasibility for practical applications in agricultural automation.
Table 5 Ablation experiments on SBDS dataset.
①	②	③	Precision	Recall	mAP0.5	mAP0.75	mAP0.5:0.95	Param.(M)	FLOPs(G)	FPS
			90.1	85.2	91.0	83.5	75.1	3.0	8.1	121.6
√			90.4	85.4	91.3	83.8	75.3	3.2	8.4	102.4
√	√		91.6	86.1	92.3	84.5	76.0	4.1	11.4	91.5
√		√	90.8	85.7	91.7	84.2	75.7	3.2	8.4	98.8
	√	√	91.8	86.3	92.4	84.7	76.1	3.9	11.0	100.3
√	√	√	92.1	86.5	92.7	84.9	76.3	4.1	11.4	87.5
We further intuitively compared the differences in strawberry ripeness detection performance between our model and the baseline model. As shown in Figure 11, the test results of the baseline model were presented in Figure 11a and c, while the results of our improved model were displayed in Figure 11 b and d. In Figure 11a, the strawberry labeled as “r” was not detected due to its overlap with another larger strawberry, reflecting the baseline model’s insufficient feature extraction capability when dealing with strawberries whose colors are similar to the background. Similarly, the high overlap between a half-ripe and a ripe strawberry led to the misdetection of two strawberries labeled as “s” as a single half-ripe strawberry, further highlighting the baseline model’s limitations in handling overlapping targets. In Figure 11c, the strawberries labeled as “t” and “u” were not detected due to their small size, revealing the baseline model’s limitations in detecting small targets. Meanwhile, the strawberry labeled as “v” was highly overlapped with another larger strawberry, which not only underscored the baseline model’s inadequacy in handling overlapping targets but also indicated its low sensitivity in recognizing strawberries at different stages of ripeness. However, our model effectively addressed the limitations of the baseline model by introducing multiple key strategies. Specifically, we enhanced the model’s feature extraction capability by integrating PCIB, significantly improved the detection of small strawberries by introducing MS-FPN, and with the help of Focaler-shape-IoU technology, increased the recognition rate of difficult strawberry samples in overlapping situations. The integrated application of these techniques enabled our model to excel in handling occlusions, recognizing small targets, and distinguishing overlapping targets, overcoming the deficiencies of the baseline model in these complex scenarios.

Figure 11 The strawberry object detection results of our model (b) and (d) compared with the baseline model (a) and (c) on the SBDS dataset. The cyan dashed circles indicate missed or falsely detected objects, while the red, blue, and yellow rectangles represent detected raw, turning, and ripe strawberries, respectively. The confidence scores are labeled at the top of the rectangles.
3.7 Comparison with State-of-the-art Models
To comprehensively evaluate the performance of the HM-YOLO model in strawberry ripeness detection, the comparative experiments were conducted between ours and the current state-of-the-art object detection algorithms on the SBDS strawberry dataset. Additionally, a set of special experiments was conducted, using YOLOv8n as the baseline model and comparing it with state-of-the-art backbone networks such as MobileNetV4, EfficientViT, and GhostNetv2. As shown in Table 6, although the Libra R-CNN exceled in performance with mAP0.5 and mAP0.5:0.95 reaching 87.6% and 71.8% respectively, its parameter count was as high as 34.3M and its computational complexity reaches 293.6G, resulting in lower computational efficiency for this two-stage model. YOLOv10n, an end-to-end network, has a parameter count of only 2.3M and a computational complexity of 6.7G, but its performance on mAP0.5 and mAP0.5:0.95 is 0.1% and 0.3% lower than YOLOv8n, respectively. This may be because YOLOv10n uses inexpensive deep convolution and pointwise convolution techniques to replace traditional convolutional downsampling and reduce the overhead of classification heads, which improves efficiency but sacrifices some performance. Although our model showed only marginal performance improvements compared to other single-stage YOLO algorithms, such as a 2.6% higher mAP0.5 compared to the classic YOLOv5n, and a 2.0% higher mAP0.5 compared to the advanced YOLOv9-tiny, it exhibited a clear advantage when compared with models using lightweight backbone networks, particularly MobileNetV4, EfficientViT, and GhostNetv2. Notably, our model outperformed the YOLOv8-GhostNetv2 by 4.6% in the critical mAP0.5. The HM-YOLO model demonstrates outstanding performance in terms of parameter count and computational complexity, significantly lower than two-stage models such as Libra R-CNN, while maintaining low computational overhead in single-stage models. This efficiency allows HM-YOLO to run smoothly in resource-constrained environments. Despite the optimization of computational resources, HM-YOLO does not significantly compromise detection performance. Compared to other single-stage models and lightweight backbone networks, HM-YOLO shows significant advantages in the critical mAP0.5 metric, proving that it can maintain efficient computation while still delivering high-precision detection results. The design philosophy of HM-YOLO makes it highly suitable for real-time applications. In agricultural environments, real-time detection of strawberry ripeness is crucial for harvest decisions, and the low memory and power requirements enable HM-YOLO to operate efficiently on edge devices, perfectly meeting the agricultural application’s demands for quick and accurate detection.
Table 6 Detection results by using different models on the SBDS dataset.
Model	Precision	Recall	mAP0.5	mAP0.5:0.95	Param.(M)	FLOPs(G)
Libra R-CNN* [33]	86.1	81.8	87.6	71.8	34.3	293.6
CenterNet [34]	84.1	80.4	85.2	70.1	32.7	70.2
EfficientDet-D0 [32]	83.4	77.6	80.7	66.9	3.7	7.4
YOLOv5n [35]	89.4	85.1	90.4	74.4	2.5	7.1
YOLOX-tiny [36]	89.7	85.3	90.6	74.5	5.1	6.5
YOLOv6n [37]	89.6	85.2	90.6	74.6	4.2	11.8
YOLO7-tiny [38]	89.9	84.8	90.8	74.8	6.0	13.2
YOLOv8n [39]	90.1	85.2	91.0	75.1	3.0	8.1
YOLOv9-tiny [40]	89.5	85.2	90.7	74.7	2.0	7.7
YOLOv10n# [41]	89.8	84.8	90.9	74.8	2.7	8.2
RTMDet-tiny [42]	87.0	82.9	88.9	72.9	4.8	8.1
YOLOv8n-MobileNetv4& [43]	87.8	82.3	87.2	71.8	4.3	8.1
YOLOv8n-EfficientViT& [44]	88.5	83.1	87.8	73.1	4.0	9.5
YOLOv8n-GhostNetv2& [45]	88.1	82.8	88.1	72.1	6.3	8.7
HM-YOLO	92.1	86.5	92.7	76.3	4.1	11.4
Note: Models marked with an asterisk (*) represents two-stage networks, those marked with a pound sign (#) denotes end-to-end networks,and those marked with an ampersand (&) are models equipped with other backbone networks, and unmarked models are classified as single-stage networks.
To more intuitively demonstrate the performance of our model in detecting strawberries at different stages of ripeness, three representative networks were selected for comparison on the SBDS dataset: the two-stage network Libra R-CNN, the advanced end-to-end YOLOv10n from the YOLO series, and the single-stage network equipped with the outstanding backbone network GhostNetv2. In Figure 12a, the YOLOv8n-GhostNetv2 failed to identify small strawberries marked with “r” and “s”, so the GhostNetv2-based detectors were not suitable for detecting strawberries in the early, unripe stage. In Figure 12b, the YOLOv10n, on the other hand, incorrectly recognized two overlapping strawberries at the position “t” as a single strawberry and missed the strawberry marked with “u”, demonstrating poor performance in strawberry detection in complex scenes. In Figure 12 c, the two-stage network of Libra R-CNN failed to identify the strawberries marked with “v” and “w”, and erroneously identified a semi-ripe strawberry marked with “x” as an unripe strawberry, highlighting limitations in recognizing the turning stage strawberries. As shown in Figure 12d, our model could successfully and accurately recognize the strawberries at three different stages of ripeness in complex scenarios, demonstrating substantial application potential.

Figure 12 Recognition outcomes of YOLOv8n-GhostNetv2 (a), YOLOv10n (b), Libra R-CNN (c), and our model (d), respectively.
4. Conclusions
This study proposes an improved model of HM-YOLO aimed at enhancing the detection performance of strawberry ripeness in complex environments. Firstly, the PCIB was designed to replace the bottleneck structure in the C2f module of the backbone network, thereby effectively extract key features of strawberries at different ripeness stages. Simultaneously, the PHAM was developed to handle the long-range dependencies and accurately locate strawberry fruit target regions at a lower computational cost. In the neck network, we integrated the MS-FPN with PHAM to precisely discern and efficiently extract fine-grained features of strawberries of various sizes. Finally, the Focaler-shape-IoU method was proposed to address the issue of imbalanced difficulty among samples of different ripeness stages, thereby further improving the accuracy of boundary box regression. Data augmentation was employed to expand 5600 images of strawberries grown in complex natural environments to 16800 images. The test results indicate that the HM-YOLO model achieved 92.1% in precision and 92.7% in mAP0.5, outperforming the original YOLOv8n model. Therefore, this technology holds significant potential for improving the quality of machine-harvested strawberry fruits.
However, several challenges must be considered for practical field deployment. Firstly, the model’s reliance on high-quality image data may encounter limitations in real-world agricultural settings, where factors such as lighting conditions, occlusions, and varying growth patterns can affect system accuracy. These challenges call for further refinement of data augmentation strategies and improvements in model robustness to ensure reliable performance under diverse environmental conditions. Additionally, the need for real-time processing in outdoor field environments imposes additional constraints on computational resources. This necessitates further optimization of the model to run efficiently on edge devices with limited processing power. Moreover, although the model has been optimized for strawberry ripeness detection, expanding its capability to handle other agricultural tasks—such as detecting fruit in dense or heavily occluded plantings—remains an important area for future development. Future research will also explore integrating the model with robotic systems for autonomous strawberry picking, taking into account the dynamics of machine mobility and interactions with the environment.
Despite these advancements, the study also presents certain limitations. Firstly, while the model categorizes strawberry ripeness into three stages, the complexity of the ripening process means that this simplification may not fully capture the continuous and gradual changes that occur throughout the strawberry’s growth cycle. To address this, future work will focus on refining the ripeness classification system, potentially incorporating more detailed stages or adopting continuous prediction models to better reflect the dynamic evolution of strawberry ripening. Secondly, although data augmentation techniques have been employed to improve the model’s robustness, the optimal image enhancement thresholds that account for the diverse morphological variations in natural strawberry growth have not yet been fully optimized. Future research will aim to fine-tune these thresholds, enhancing the model’s performance across a broader range of natural growth conditions and ensuring better generalization to varying environmental factors.
Author Contributions: Conceptualization, methodology, and software, Y.G.; data curation, X.R. and H.L.; writing—review and editing, Y.G., X.R., H.L., Y.C and P.L.; supervision and project administration, Y.C. and P.L. All authors read and agreed to the published version of this manuscript.
Funding: This research received no external funding

Institutional Review Board Statement: Not applicable.

Informed Consent Statement: Not applicable.

Data Availability Statement: Dataset available on request from the authors.

Conflicts of Interest: The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
